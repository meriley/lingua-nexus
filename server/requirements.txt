fastapi>=0.104.0,<0.110.0
uvicorn>=0.24.0,<0.30.0
pydantic>=2.0.0,<3.0.0
transformers>=4.36.0,<4.41.0
torch>=2.1.0,<2.2.0
sentencepiece==0.1.99
slowapi==0.1.7
python-dotenv==1.0.0
python-multipart==0.0.6
typing_extensions>=4.4.0
accelerate>=0.18.0
tokenizers>=0.15.0
bitsandbytes>=0.37.0
llama-cpp-python>=0.2.0
huggingface-hub>=0.19.0

# Adaptive Translation Chunking System Dependencies
sentence-transformers>=2.2.0,<3.0.0  # For semantic similarity and discourse analysis (PyTorch 2.1 compatible)
redis>=4.5.0                  # Multi-level caching infrastructure
prometheus-client>=0.16.0     # Metrics collection and monitoring
nltk>=3.8                     # Natural language processing for chunking
numpy>=1.24.0                 # Numerical operations for quality scoring
scikit-learn>=1.3.0          # ML utilities for quality assessment
asyncio-throttle>=1.0.2      # Rate limiting and throttling
redis[hiredis]>=4.5.0        # Redis client with async support and hiredis parser
psutil>=5.9.0                 # System resource monitoring