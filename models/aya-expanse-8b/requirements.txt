# Aya Expanse 8B model requirements
# Optimized for GGUF format with transformers fallback

# Web framework dependencies
fastapi>=0.115.0
uvicorn[standard]>=0.30.0
python-multipart>=0.0.6

# Core dependencies
torch>=2.0.0
transformers>=4.30.0
tokenizers>=0.13.0
pydantic>=2.0.0

# HuggingFace ecosystem
huggingface-hub>=0.16.0
accelerate>=0.20.0

# GGUF support (primary format)
llama-cpp-python>=0.2.0

# Quantization support (fallback)
bitsandbytes>=0.41.0

# Server dependencies
sentencepiece>=0.1.99
slowapi>=0.1.7
python-dotenv>=1.0.0
sentence-transformers>=2.2.0
redis[hiredis]>=4.5.0
prometheus-client>=0.16.0
nltk>=3.8
scikit-learn>=1.3.0
asyncio-throttle>=1.0.2
psutil>=5.9.0

# Utilities
numpy>=1.21.0
torchaudio>=2.0.0

# Optional GPU acceleration
# Uncomment if using CUDA-enabled llama-cpp-python
# llama-cpp-python[cublas]>=0.2.0

# Development dependencies (optional)
# pytest>=7.0.0
# pytest-asyncio>=0.21.0